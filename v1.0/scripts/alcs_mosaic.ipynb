{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Spitzer mosaics from raw pipeline files\n",
    "\n",
    "0) Define root=CHArGE name of the filed (i.e. j224900m4432)\n",
    "\n",
    "1) Download reddest filter mosaic from, e.g. (this step is automatic, however verify that filenames in the URL match\n",
    "   the ones in the notebook \n",
    "   https://s3.amazonaws.com/grizli-v1/Pipeline/j210604m5845/Prep/j210604m5845.summary.html\n",
    "\n",
    "2) The next cell would query the Spitzer SHA archive around the target position, e.g., \n",
    "https://sha.ipac.caltech.edu/applications/Spitzer/SHA/#id=SearchByPosition&RequestClass=ServerRequest&DoSearch=true&SearchByPosition.field.radius=0.13888889000000001&UserTargetWorldPt=316.52057;-58.74497;EQ_J2000&SimpleTargetPanel.field.resolvedBy=nedthensimbad&MoreOptions.field.prodtype=aor,pbcd,bcd&shortDesc=Position&isBookmarkAble=true&isDrillDownRoot=true&isSearchResult=true\n",
    "\n",
    "3) Download \"Level 1 Products, Including Ancillary\" (manual outside of the notebook).\n",
    "\n",
    "4) Drizzle properties of the preliminary mosaic, here you can define the pixel fraction, pixel size and the kernel\n",
    "   that would be used to drizzle the exposures. It is generally recommended to use pixfrac=0.2 pix=1.0 \n",
    "   and kernel='square', however if you have a lot of exposures (e.g. Hubble Frontier Fields), you may also try\n",
    "   kernel='point', which would set the pixfrac=0.0.\n",
    "   \n",
    "5) Define output WCS to encompass all Spitzer exposures and that is also aligned in integer pixel phase with the HST image.\n",
    "\n",
    "6) Reprocess by filter / by AOR\n",
    "\n",
    "    - Fine alignment to GAIA DR2, accounting for proper motions at observation epoch\n",
    "    - Background subtraction\n",
    "    - Generate AOR-level PSFs in rectified and detector frame\n",
    "    \n",
    "7) Drizzle a final mosaic on an output grid that encompasses the HST pointing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.path import Path\n",
    "\n",
    "from skimage.morphology import binary_dilation\n",
    "\n",
    "import astropy.io.fits as pyfits\n",
    "import astropy.wcs as pywcs\n",
    "import astropy.units as u\n",
    "\n",
    "import drizzlepac\n",
    "from drizzlepac.astrodrizzle import ablot\n",
    "\n",
    "from grizli import utils\n",
    "\n",
    "# Need to move these to public repo\n",
    "from golfir import irac \n",
    "from golfir.utils import get_wcslist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use CHArGE naming convention\n",
    "\n",
    "root = 'j224900m4432'\n",
    "\n",
    "PATH = '/Users/vasily/documents/PhD/Projects/IRAC/HST/CHArGE/IRAC/'+root\n",
    "try:\n",
    "    os.mkdir(PATH)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "os.chdir(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download files \n",
    "for ext in ['_phot.fits', '-f160w_drz_sci.fits.gz', '-f160w_drz_wht.fits.gz', \n",
    "            '-f160w_psf.fits', '-ir_drz_sci.fits.gz', '-ir_drz_wht.fits.gz', '-ir_seg.fits.gz']:\n",
    "    file=root+ext\n",
    "    file_hff=('hff-')+file\n",
    "    root_hff=('hff-')+root\n",
    "    if len(glob.glob(file.strip('.gz')+'*')) == 0:\n",
    "        print(file)\n",
    "        #print('https://s3.amazonaws.com/grizli-v1/Pipeline/'+str(root)+'/Prep/'+str(file))\n",
    "        os.system(f'wget -O {file_hff} https://s3.amazonaws.com/grizli-v1/Pipeline/{root_hff}/Prep/{file_hff}')\n",
    "\n",
    "# Gunzip\n",
    "os.system('gunzip *fits.gz')\n",
    "\n",
    "# Copy of the catalog for IRAC photometry\n",
    "if not os.path.exists(f'{root}_irac_phot.fits'):\n",
    "    os.system(f'cp {root}_phot.fits {root}_irac_phot.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate SHA URL that can be used to download the exposures\n",
    "phot = utils.read_catalog(f'{root}_phot.fits')\n",
    "ra, dec = np.median(phot['ra']), np.median(phot['dec'])\n",
    "\n",
    "radius = 10. # arcmin, 10 was used to create these mosaics\n",
    "\n",
    "URL = \"https://sha.ipac.caltech.edu/applications/Spitzer/SHA/#id=SearchByPosition&\"\n",
    "URL += f\"RequestClass=ServerRequest&DoSearch=true&SearchByPosition.field.radius={radius/60:.5f}\"\n",
    "URL += f\"&UserTargetWorldPt={ra};{dec};EQ_J2000&SimpleTargetPanel.field.resolvedBy=nedthensimbad&\"\n",
    "URL += \"MoreOptions.field.prodtype=aor,pbcd,bcd&shortDesc=Position&isBookmarkAble=true&isDrillDownRoot=true&\"\n",
    "URL += \"isSearchResult=true\"\n",
    "\n",
    "print(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip the SHA zip files\n",
    "files = glob.glob('tgt*zip')\n",
    "files.sort()\n",
    "\n",
    "import shutil\n",
    "os.mkdir('targs')\n",
    "for file in files:\n",
    "    print(file)\n",
    "    os.system(f'unzip -n {file}')\n",
    "    shutil.move(file,'targs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drizzle properties of the preliminary mosaic\n",
    "pixfrac, pix, kernel = 0.2, 1.0, 'square'  # 0.2, 1.0, 'square' are default settings, if Nexp is large \n",
    "                                           #these can be changed to point kernel (pixfrac=0.0)\n",
    "                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an output WCS aligned in pixel phase to the HST mosaic ()\n",
    "\n",
    "if not os.path.exists('ref_hdu.fits'):\n",
    "    wcslist = get_wcslist(skip=10)\n",
    "    out_hdu = utils.make_maximal_wcs(wcslist, pixel_scale=pix, theta=0, pad=5, get_hdu=True, verbose=True)\n",
    "    \n",
    "    # Make sure pixels align\n",
    "    ref_file = glob.glob('{0}-f1*_drz_sci.fits'.format(root))[-1]\n",
    "    \n",
    "    print(f'\\nHST reference image: {ref_file}\\n')\n",
    "    \n",
    "    ref_hdu = pyfits.open(ref_file)[0].header\n",
    "    ref_filter = utils.get_hst_filter(ref_hdu).lower()\n",
    "    \n",
    "    ref_wcs = pywcs.WCS(ref_hdu)\n",
    "    ref_rd = ref_wcs.all_pix2world(np.array([[-0.5, -0.5]]), 0).flatten()\n",
    "    target_phase = np.array([0.5, 0.5])#/(pix/0.1)\n",
    "    for k in ['RADESYS', 'LATPOLE', 'LONPOLE']:\n",
    "        out_hdu.header[k] = ref_hdu[k]\n",
    "        \n",
    "    # Shift CRVAL to same tangent point\n",
    "    out_wcs = pywcs.WCS(out_hdu.header)\n",
    "    out_xy = out_wcs.all_world2pix(np.array([ref_wcs.wcs.crval]), 1).flatten()\n",
    "    out_hdu.header['CRVAL1'], out_hdu.header['CRVAL2'] = tuple(ref_wcs.wcs.crval)\n",
    "    out_hdu.header['CRPIX1'], out_hdu.header['CRPIX2'] = tuple(out_xy)\n",
    "    \n",
    "    # Align integer pixel phase\n",
    "    out_wcs = pywcs.WCS(out_hdu.header)\n",
    "    out_xy = out_wcs.all_world2pix(np.array([ref_rd]), 0).flatten()\n",
    "    xy_phase = out_xy - np.floor(out_xy)\n",
    "    new_crpix = out_wcs.wcs.crpix - (xy_phase - target_phase)\n",
    "    out_hdu.header['CRPIX1'], out_hdu.header['CRPIX2'] = tuple(new_crpix)\n",
    "    out_wcs = pywcs.WCS(out_hdu.header)\n",
    "    \n",
    "    out_hdu.writeto('ref_hdu.fits', output_verify='Fix')\n",
    "    \n",
    "else:\n",
    "    out_hdu = pyfits.open('ref_hdu.fits')[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up by Spitzer \"channel\" (filter, instrument)\n",
    "\n",
    "Probably you'll just want channels 1 and 2, but the scripts should work for all IRAC channels and MIPS 24 um."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_frametime = 20\n",
    "\n",
    "query = 'r*'\n",
    "files = glob.glob('{0}/ch*/bcd/SPITZER_I*cbcd.fits'.format(query))\n",
    "files += glob.glob('{0}/ch*/bcd/SPITZER_I*xbcd.fits.gz'.format(query))\n",
    "files += glob.glob('{0}/ch*/bcd/SPITZER_M*ebcd.fits'.format(query))\n",
    "files.sort()\n",
    "\n",
    "roots = np.array([file.split('/')[0] for file in files])\n",
    "channels = np.array([file.split('_')[1] for file in files])\n",
    "all_roots = np.array(['{0}-{1}'.format(r, c.replace('I','ch').replace('M', 'mips')) for r, c in zip(roots, channels)])\n",
    "\n",
    "tab = {'aor':[], 'N':[], 'channel':[]}\n",
    "for r in np.unique(all_roots):\n",
    "    tab['aor'].append(r.split('-')[0])\n",
    "    tab['N'].append((all_roots == r).sum())\n",
    "    tab['channel'].append(r.split('-')[1])\n",
    "\n",
    "aors = utils.GTable(tab)\n",
    "print(aors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SKIP = True          # Don't regenerate finished files\n",
    "delete_group = False # Delete intermediate products from memory\n",
    "zip_outputs = False    # GZip intermediate products\n",
    "\n",
    "channels = ['ch1','ch2','ch3','ch4','mips1']\n",
    "aors_ch = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reprocess the mosaics by AOR\n",
    "\n",
    "This loop pretty much does everything to make the final mosaics and generates empirical PSFs based on GAIA stars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process in groups, helps for fields like HFF with dozens/hundreds of AORs!\n",
    "for ch in channels:\n",
    "    \n",
    "    aor = aors[(aors['channel'] == ch) & (aors['N'] > 5)]\n",
    "    if len(aor) == 0:\n",
    "        continue\n",
    "    \n",
    "    #aors_ch[ch] = []\n",
    "        \n",
    "    if ch in ['ch1','ch2']:\n",
    "        NPER, instrument, min_frametime = 500, 'irac', 10\n",
    "    if ch in ['ch3','ch4']:\n",
    "        NPER, instrument, min_frametime = 500, 'irac', 10\n",
    "        #NPER, instrument, min_frametime = 800, 'irac', 20\n",
    "    elif ch in ['mips1']:\n",
    "        NPER, instrument, min_frametime, pix = 400, 'mips', 2, 1.0\n",
    "\n",
    "    nsort = np.cumsum(aor['N']/NPER)\n",
    "    NGROUP = int(np.ceil(nsort.max()))\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for g in range(NGROUP):\n",
    "        root_i = root+'-{0:02d}'.format(g)\n",
    "    \n",
    "        gsel = (nsort > g) & (nsort <= g+1)\n",
    "        aor_ids = list(aor['aor'][gsel])\n",
    "        print('{0}-{1}   N_AOR = {2:>2d}  N_EXP = {3:>4d}'.format(root_i, ch,  len(aor_ids), aor['N'][gsel].sum()))\n",
    "        count += gsel.sum()\n",
    "    \n",
    "        files = glob.glob('{0}-{1}*'.format(root_i, ch))\n",
    "        if (len(files) > 0) & (SKIP): \n",
    "            print('Skip {0}-{1}'.format(root_i, ch))\n",
    "            continue\n",
    "\n",
    "        # Do internal alignment to GAIA.  \n",
    "        # Otherwise, set `radec` to the name of a file that has two columns with \n",
    "        # reference ra/dec.\n",
    "        radec = None \n",
    "\n",
    "        # Pipeline\n",
    "        if instrument == 'mips':\n",
    "            aors_ch[ch] = irac.process_all(channel=ch.replace('mips','ch'), output_root=root_i, \n",
    "                                           driz_scale=pix, kernel=kernel, pixfrac=pixfrac, wcslist=None, \n",
    "                                           pad=0, out_hdu=out_hdu, aor_ids=aor_ids, flat_background=False, \n",
    "                                           two_pass=True, min_frametime=min_frametime, instrument=instrument, \n",
    "                                           align_threshold=0.15, radec=radec, run_alignment=False, \n",
    "                                           mips_ext='_ebcd.fits')\n",
    "        else:\n",
    "            aors_ch[ch] = irac.process_all(channel=ch, output_root=root_i, \n",
    "                                           driz_scale=pix, kernel=kernel, pixfrac=pixfrac, wcslist=None, \n",
    "                                           pad=0, out_hdu=out_hdu, aor_ids=aor_ids, flat_background=False, \n",
    "                                           two_pass=True, min_frametime=min_frametime, instrument=instrument, \n",
    "                                           radec=radec)\n",
    "    \n",
    "        if len(aors_ch[ch]) == 0:\n",
    "            continue\n",
    "            \n",
    "        # PSFs\n",
    "        plt.ioff()\n",
    "        \n",
    "        if instrument != 'mips':\n",
    "            psf_size=20\n",
    "            ch_num = int(ch[-1])\n",
    "            segmask=True\n",
    "            for p in [0.1, pix]:\n",
    "                irac.mosaic_psf(output_root=root_i, target_pix=p, channel=ch_num, aors=aors_ch[ch], \n",
    "                                kernel=kernel, pixfrac=pixfrac, size=psf_size, native_orientation=False, \n",
    "                                instrument=instrument, subtract_background=False, segmentation_mask=segmask, \n",
    "                                max_R=10)\n",
    "                plt.close('all')\n",
    "    \n",
    "            psf_size=30\n",
    "            p = 0.1\n",
    "            irac.mosaic_psf(output_root=root_i, target_pix=p, channel=ch_num, aors=aors_ch[ch], \n",
    "                            kernel=kernel, pixfrac=pixfrac, size=psf_size, native_orientation=True, \n",
    "                            subtract_background=False, segmentation_mask=segmask, max_R=10)\n",
    "                        \n",
    "            plt.close('all')\n",
    "            \n",
    "        if delete_group:\n",
    "            del(aors_ch[ch])\n",
    "        \n",
    "        print('Done {0}-{1}, gzip products'.format(root_i, ch))\n",
    "        \n",
    "        if zip_outputs:\n",
    "            os.system('gzip {0}*-{1}_drz*fits'.format(root_i, ch))\n",
    "    \n",
    "    if instrument != 'mips':\n",
    "        # Average PSF\n",
    "        p = 0.1\n",
    "        files = glob.glob('*{0}-{1:.1f}*psfr.fits'.format(ch, p))\n",
    "        files.sort()\n",
    "        avg = None\n",
    "        for file in files: \n",
    "            im = pyfits.open(file)\n",
    "            if avg is None:\n",
    "                wht = im[0].data != 0\n",
    "                avg = im[0].data*wht\n",
    "            else:\n",
    "                wht_i = im[0].data != 0\n",
    "                avg += im[0].data*wht_i\n",
    "                wht += wht_i\n",
    "\n",
    "        avg = avg/wht\n",
    "        avg[wht == 0] = 0\n",
    "    \n",
    "        # Window\n",
    "        from photutils import (HanningWindow, TukeyWindow, CosineBellWindow,\n",
    "                               SplitCosineBellWindow, TopHatWindow)\n",
    "\n",
    "        coswindow = CosineBellWindow(alpha=1)\n",
    "        avg *= coswindow(avg.shape)**0.05\n",
    "        avg /= avg.sum()\n",
    "    \n",
    "        pyfits.writeto('{0}-{1}-{2:0.1f}.psfr_avg.fits'.format(root, ch, p), data=avg, \n",
    "                       header=im[0].header, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Show the product\n",
    "files = glob.glob(f'{root}-00-ch*sci.fits')\n",
    "files.sort()\n",
    "\n",
    "fig = plt.figure(figsize=[14, 7])\n",
    "for i, file in enumerate(files[:2]):\n",
    "    im = pyfits.open(file)\n",
    "    print('{0} {1} {2:.1f} s'.format(file, im[0].header['FILTER'], im[0].header['EXPTIME']))\n",
    "    ax = fig.add_subplot(1,2,1+i)\n",
    "    ax.imshow(im[0].data, vmin=-0.1, vmax=1, cmap='gray_r')\n",
    "    ax.text(0.05, 0.95, file, ha='left', va='top', color='k', \n",
    "            transform=ax.transAxes)\n",
    "    \n",
    "if 0:\n",
    "    # Zoom in\n",
    "    x0, y0, N = 600, 600, 50\n",
    "    for ax in fig.axes:\n",
    "        ax.set_xlim(x0-N, x0+N)\n",
    "        ax.set_ylim(y0-N, y0+N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make more compact individual exposures and clean directories\n",
    "wfiles = glob.glob('r*/*/bcd/*_I[1-4]_*wcs.fits')\n",
    "#wfiles = glob.glob('r*/*/bcd/*_M[1-4]_*wcs.fits')\n",
    "wfiles.sort()\n",
    "for wcsfile in wfiles:\n",
    "    outfile = wcsfile.replace('_wcs.fits', '_xbcd.fits.gz')\n",
    "    if os.path.exists(outfile):\n",
    "        print(outfile)\n",
    "    else:\n",
    "        irac.combine_products(wcsfile)\n",
    "        print('Run: ', outfile)\n",
    "    \n",
    "    if os.path.exists(outfile):\n",
    "        remove_files = glob.glob('{0}*fits'.format(wcsfile.split('_wcs')[0]))\n",
    "        for f in remove_files:\n",
    "            print('   rm ', f)\n",
    "            os.remove(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drizzle final mosaics\n",
    "\n",
    "Here this doesn't do much, but if you had many AORs you want to recombine all of the images into a final mosaic with new drizzle parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make final mosaic a bit bigger than the HST image\n",
    "pad = 1.1\n",
    "\n",
    "# Pixel scale of final mosaic.\n",
    "# Don't make too small if not many dithers available as in this example.\n",
    "# But for well-sampled mosaics like RELICS / HFF, can push this to perhaps 0.3\" / pix\n",
    "pixscale = 0.5 #0.5 is the default setting \n",
    "\n",
    "# Again, if have many dithers maybe can use more aggressive drizzle parameters,\n",
    "# like a 'point' kernel or smaller pixfrac (a 'point' kernel is pixfrac=0)\n",
    "kernel, pixfrac = 'square', 0.2 #square, 0.2 is the default setting\n",
    "\n",
    "# Correction for bad columns near bright stars\n",
    "pulldown_mag = 16.2 \n",
    "\n",
    "##############\n",
    "# Dilation for CR rejection\n",
    "dil = np.ones((3,3))\n",
    "driz_cr = [7, 4]\n",
    "blot_interp = 'poly5'\n",
    "bright_fmax = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ch in ['ch1', 'ch2', 'ch3', 'ch4'][:2]:\n",
    "    ###########\n",
    "    # Files and reference image for extra CR rejection\n",
    "    if ch == 'mips1':\n",
    "        files = glob.glob('r*/ch1/bcd/SPITZER_M1_*xbcd.fits*'.format(ch))\n",
    "        files.sort()\n",
    "        pulldown_mag = -10\n",
    "    else:\n",
    "        files = glob.glob('r*/{0}/bcd/*_I?_*xbcd.fits*'.format(ch))\n",
    "        files.sort()\n",
    "\n",
    "    #ref = pyfits.open('{0}-00-{1}_drz_sci.fits'.format(root, ch))\n",
    "    #ref_data = ref[0].data.astype(np.float32)\n",
    "\n",
    "    ref_files = glob.glob(f'{root}-??-{ch}*sci.fits')\n",
    "    \n",
    "    num = None\n",
    "    for ref_file in ref_files:\n",
    "        ref = pyfits.open(ref_file)\n",
    "        wht = pyfits.open(ref_file.replace('_sci.fits', '_wht.fits'))\n",
    "        if num is None:\n",
    "            num = ref[0].data*wht[0].data\n",
    "            den = wht[0].data\n",
    "        else:\n",
    "            num += ref[0].data*wht[0].data\n",
    "            den += wht[0].data\n",
    "    \n",
    "    ref_data = (num/den).astype(np.float32)\n",
    "    ref_data[den <= 0] = 0\n",
    "    \n",
    "    ref_wcs = pywcs.WCS(ref[0].header, relax=True) \n",
    "    ref_wcs.pscale = utils.get_wcs_pscale(ref_wcs)\n",
    "    \n",
    "    \n",
    "\n",
    "    ##############\n",
    "    # Output WCS based on HST footprint\n",
    "    hst_im = pyfits.open('{0}-f160w_drz_sci.fits'.format(root))\n",
    "    hst_wcs = pywcs.WCS(hst_im[0])\n",
    "    hst_wcs.pscale = utils.get_wcs_pscale(hst_wcs)\n",
    "    \n",
    "    try:\n",
    "        size = (np.round(np.array([hst_wcs._naxis1, hst_wcs._naxis2])*hst_wcs.pscale*pad/pixscale)*pixscale)\n",
    "    except:\n",
    "        size = (np.round(np.array([hst_wcs._naxis[0], hst_wcs._naxis[1]])*hst_wcs.pscale*pad/pixscale)*pixscale)\n",
    "\n",
    "    #size = (np.round(np.array([hst_wcs._naxis1, hst_wcs._naxis2])*hst_wcs.pscale*pad/pixscale)*pixscale)\n",
    "\n",
    "    out_header, out_wcs = utils.make_wcsheader(ra=hst_wcs.wcs.crval[0], \n",
    "                                               dec=hst_wcs.wcs.crval[1], size=size, \n",
    "                                               pixscale=pixscale, get_hdu=False, theta=0)\n",
    "\n",
    "    ##############\n",
    "    # Bright stars for pulldown correction\n",
    "    ph = utils.read_catalog('{0}-00-{1}.cat.fits'.format(root, ch)) \n",
    "    bright = (ph['mag_auto'] < pulldown_mag) # & (ph['flux_radius'] < 3)\n",
    "    ph = ph[bright]\n",
    "\n",
    "    ##############\n",
    "    # Now do the drizzling\n",
    "    yp, xp = np.indices((256, 256))\n",
    "    orig_files = []\n",
    "\n",
    "    out_header['DRIZ_CR0'] = driz_cr[0]\n",
    "    out_header['DRIZ_CR1'] = driz_cr[1]\n",
    "    out_header['KERNEL'] = kernel\n",
    "    out_header['PIXFRAC'] = pixfrac\n",
    "    out_header['NDRIZIM'] = 0\n",
    "    out_header['EXPTIME'] = 0\n",
    "    out_header['BUNIT'] = 'microJy'\n",
    "    out_header['FILTER'] = ch\n",
    "    \n",
    "    med_root = 'xxx'\n",
    "    N = len(files)\n",
    "\n",
    "    for i, file in enumerate(files):#[:100]):\n",
    "\n",
    "        print('{0}/{1} {2}'.format(i, N, file))\n",
    "\n",
    "        if file in orig_files:\n",
    "            continue\n",
    "\n",
    "        im = pyfits.open(file)\n",
    "        ivar = 1/im['CBUNC'].data**2    \n",
    "        msk = (~np.isfinite(ivar)) | (~np.isfinite(im['CBCD'].data))\n",
    "        im['CBCD'].data[msk] = 0\n",
    "        ivar[msk] = 0\n",
    "\n",
    "        wcs = pywcs.WCS(im['WCS'].header, relax=True)\n",
    "        wcs.pscale = utils.get_wcs_pscale(wcs)\n",
    "        fp = Path(wcs.calc_footprint())\n",
    "\n",
    "        med_root_i = im.filename().split('/')[0]\n",
    "        if med_root != med_root_i:\n",
    "            print('\\n Read {0}-{1}_med.fits \\n'.format(med_root_i, ch))\n",
    "            med = pyfits.open('{0}-{1}_med.fits'.format(med_root_i, ch))\n",
    "            med_data = med[0].data.astype(np.float32)\n",
    "            med_root = med_root_i\n",
    "\n",
    "            try:\n",
    "                gaia_rd = utils.read_catalog('{0}-{1}_gaia.radec'.format(med_root_i, ch))\n",
    "                ii, rr = gaia_rd.match_to_catalog_sky(ph)\n",
    "                gaia_rd = gaia_rd[ii][rr.value < 2]\n",
    "                gaia_pts = np.array([gaia_rd['ra'].data, gaia_rd['dec'].data]).T\n",
    "            except:\n",
    "                gaia_rd = []\n",
    "\n",
    "        #data = im['CBCD'].data - aor_med[0].data\n",
    "\n",
    "        # Change output units to uJy / pix\n",
    "        if ch == 'mips1':\n",
    "            # un = 1*u.MJy/u.sr\n",
    "            # #to_ujy_px = un.to(u.uJy/u.arcsec**2).value*(out_wcs.pscale**2)\n",
    "            # to_ujy_px = un.to(u.uJy/u.arcsec**2).value*(native_scale**2)\n",
    "            to_ujy_px = 146.902690\n",
    "        else:\n",
    "            to_ujy_px = 35.17517196810\n",
    "\n",
    "        blot_data = ablot.do_blot(ref_data, ref_wcs, wcs, 1, coeffs=True, interp=blot_interp, \n",
    "                                  sinscl=1.0, stepsize=10, wcsmap=None)/to_ujy_px\n",
    "\n",
    "        # mask for bright stars\n",
    "        eblot = 1-np.clip(blot_data, 0, bright_fmax)/bright_fmax\n",
    "\n",
    "        # Initial CR\n",
    "        clean = im[0].data - med[0].data - im['WCS'].header['PEDESTAL']\n",
    "        dq = (clean - blot_data)*np.sqrt(ivar)*eblot > driz_cr[0]\n",
    "\n",
    "        # Adjacent CRs\n",
    "        dq_dil = binary_dilation(dq, selem=dil)\n",
    "        dq |= ((clean - blot_data)*np.sqrt(ivar)*eblot > driz_cr[1]) & (dq_dil)\n",
    "\n",
    "        # Very negative pixels\n",
    "        dq |= clean*np.sqrt(ivar) < -4\n",
    "\n",
    "        original_dq = im['WCS'].data - (im['WCS'].data & 1)\n",
    "        dq |= original_dq > 0\n",
    "\n",
    "        # Pulldown correction for bright stars\n",
    "        if len(gaia_rd) > 0:       \n",
    "            mat = fp.contains_points(gaia_pts) \n",
    "            if mat.sum() > 0:\n",
    "                xg, yg = wcs.all_world2pix(gaia_rd['ra'][mat], gaia_rd['dec'][mat], 0)\n",
    "                sh = dq.shape\n",
    "                mat = (xg > 0) & (xg < sh[1]) & (yg > 0) & (yg < sh[0])\n",
    "                if mat.sum() > 0:\n",
    "                    for xi, yi in zip(xg[mat], yg[mat]):\n",
    "                        dq |= (np.abs(xp-xi) < 2) & (np.abs(yp-yi) > 10)\n",
    "\n",
    "        if i == 0:\n",
    "            res = utils.drizzle_array_groups([clean], [ivar*(dq == 0)], [wcs], outputwcs=out_wcs, \n",
    "                                             kernel=kernel, pixfrac=pixfrac, data=None)\n",
    "            # Copy header keywords\n",
    "            wcs_header = utils.to_header(wcs)\n",
    "            for k in im[0].header:\n",
    "                if (k not in ['', 'HISTORY', 'COMMENT']) & (k not in out_header) & (k not in wcs_header):\n",
    "                    out_header[k] = im[0].header[k]\n",
    "                \n",
    "        else:\n",
    "            _ = utils.drizzle_array_groups([clean], [ivar*(dq == 0)], [wcs], outputwcs=out_wcs, \n",
    "                                           kernel=kernel, pixfrac=pixfrac, data=res[:3])\n",
    "\n",
    "        out_header['NDRIZIM'] += 1\n",
    "        out_header['EXPTIME'] += im[0].header['EXPTIME']\n",
    "\n",
    "    # Pixel scale factor for weights\n",
    "    wht_scale = (out_wcs.pscale/wcs.pscale)**-4\n",
    "\n",
    "    # Write final images\n",
    "    pyfits.writeto('{0}-{1}_drz_sci.fits'.format(root, ch), data=res[0]*to_ujy_px, header=out_header, \n",
    "                   output_verify='fix', overwrite=True)\n",
    "    pyfits.writeto('{0}-{1}_drz_wht.fits'.format(root, ch), data=res[1]*wht_scale/to_ujy_px**2, \n",
    "                   header=out_header, output_verify='fix', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Show the final products\n",
    "files = glob.glob(f'{root}-ch*sci.fits')\n",
    "files.sort()\n",
    "\n",
    "fig = plt.figure(figsize=[14, 7])\n",
    "for i, file in enumerate(files[:2]):\n",
    "    im = pyfits.open(file)\n",
    "    print('{0} {1} {2:.1f} s'.format(file, im[0].header['FILTER'], im[0].header['EXPTIME']))\n",
    "    ax = fig.add_subplot(1,2,1+i)\n",
    "    ax.imshow(im[0].data, vmin=-0.1/4, vmax=1/4, cmap='gray_r')\n",
    "    ax.text(0.05, 0.95, file, ha='left', va='top', color='k', \n",
    "            transform=ax.transAxes)\n",
    "    \n",
    "if 0:\n",
    "    # Zoom in, about the same position\n",
    "    x0, y0, N = 800, 880, 100\n",
    "    for ax in fig.axes:\n",
    "        ax.set_xlim(x0-N, x0+N)\n",
    "        ax.set_ylim(y0-N, y0+N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The pulldown correction was a little overzealous.  \n",
    "\n",
    "# Check the output mosaics in detail to verify\n",
    "# that pixscale / pixfrac not too small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
